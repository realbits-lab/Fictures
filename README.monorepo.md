# Fictures - AI Story Writing Platform (Monorepo)

> **Next.js 15 + Python FastAPI** - Complete platform with local AI model serving

## ğŸ—ï¸ Monorepo Structure

```
Fictures/
â”œâ”€â”€ apps/
â”‚   â”œâ”€â”€ web/          # Next.js 15 story writing platform
â”‚   â””â”€â”€ ai-server/    # Python FastAPI for local AI models
â”œâ”€â”€ packages/
â”‚   â””â”€â”€ api-client/   # TypeScript client for AI server
â””â”€â”€ docs/             # Documentation
```

## ğŸš€ Quick Start

### Prerequisites
- Node.js 18+
- Python 3.11+
- pnpm 9+

### 1. Clone and Setup

```bash
# Clone repository
git clone https://github.com/realbits-lab/Fictures.git
cd Fictures

# Install dependencies
pnpm install

# Setup Python environment
cd apps/ai-server
python -m venv venv
source venv/bin/activate  # macOS/Linux
pip install -r requirements.txt
cd ../..
```

### 2. Configure Environment

```bash
# Copy environment template (if you have one)
cp .env.example apps/web/.env.local

# Add your environment variables
# - Database (Neon PostgreSQL)
# - Authentication (NextAuth.js)
# - AI Gateway
# - Blob Storage
```

### 3. Run Development Servers

```bash
# Run both Next.js and AI server
pnpm dev

# Or run individually
pnpm dev:web    # Next.js on :3000
pnpm dev:ai     # FastAPI on :8000
```

### 4. Access Applications

- **Web App**: http://localhost:3000
- **AI Server API Docs**: http://localhost:8000/docs
- **AI Server Health**: http://localhost:8000/health

## ğŸ“¦ What's Included

### Next.js Web App (`apps/web`)
- âœ… **Next.js 15** with App Router
- âœ… **Novel Generation** - Adversity-Triumph Engine
- âœ… **Database** - PostgreSQL (Neon) with Drizzle ORM
- âœ… **Authentication** - NextAuth.js v5 (Google OAuth + Email/Password)
- âœ… **AI Integration** - Gemini 2.5 Flash via Vercel AI SDK
- âœ… **Image Storage** - Vercel Blob
- âœ… **Styling** - Tailwind CSS v4
- âœ… **Testing** - Jest + Playwright

### Python AI Server (`apps/ai-server`)
- âœ… **FastAPI** with automatic OpenAPI docs
- âœ… **Text Generation** API endpoint
- âœ… **Image Generation** API endpoint
- âœ… **CORS** configured for Next.js
- âœ… **Hot Reload** with uvicorn
- âœ… **Type Safety** with Pydantic schemas

### TypeScript API Client (`packages/api-client`)
- âœ… **Type-Safe** client for AI server
- âœ… **Auto-Generated** types from OpenAPI schema
- âœ… **Easy Integration** with Next.js

## ğŸ¯ Key Features

### Story Generation
- **Novel Generation**: Multi-phase generation (summary â†’ characters â†’ settings â†’ parts â†’ chapters â†’ scenes)
- **Scene Quality**: Automated evaluation and improvement
- **Image Generation**: Story covers, character portraits, scene illustrations
- **Moral Framework**: Adversity-Triumph Engine methodology

### Local AI Models
- **Text Generation**: Use Llama, Mistral, or other local LLMs
- **Image Generation**: Stable Diffusion XL, FLUX, or custom models
- **Cost Savings**: No cloud API costs
- **Privacy**: Data never leaves your infrastructure

### Type Safety
- **Python â†’ TypeScript**: Pydantic models generate TypeScript types
- **Compile-Time Errors**: Catch API contract violations early
- **Auto-Complete**: Full IDE support for AI endpoints

## ğŸ“– Documentation

### Essential Guides
- **[MIGRATION-SUMMARY.md](MIGRATION-SUMMARY.md)** - Quick start (if migrating)
- **[MONOREPO-SETUP.md](MONOREPO-SETUP.md)** - Complete setup guide
- **[docs/monorepo-architecture.md](docs/monorepo-architecture.md)** - Architecture overview
- **[CLAUDE.md](CLAUDE.md)** - Development guidelines

### Component Documentation
- **[apps/ai-server/README.md](apps/ai-server/README.md)** - AI server setup
- **[packages/api-client/README.md](packages/api-client/README.md)** - API client usage

### Feature Documentation
- **Novel Generation**: `docs/novels/` (specification, development, testing)
- **Image System**: `docs/image/` (generation, optimization)

## ğŸ› ï¸ Development Commands

```bash
# Development
pnpm dev              # Run both servers
pnpm dev:web          # Next.js only
pnpm dev:ai           # AI server only

# Building
pnpm build            # Build Next.js app

# Database
pnpm db:generate      # Generate migrations
pnpm db:migrate       # Run migrations
pnpm db:studio        # Open Drizzle Studio

# Testing
pnpm test             # Run Jest tests
pnpm test:watch       # Watch mode

# Type Generation (AI Client)
cd packages/api-client
pnpm generate         # Generate types from AI server
```

## ğŸ”§ Adding Local AI Models

### Text Generation (Llama Example)

1. **Download model**:
```bash
cd apps/ai-server/models/text
# Download from Hugging Face
huggingface-cli download meta-llama/Llama-3.2-3B
```

2. **Implement loading** in `apps/ai-server/src/services/text_service.py`:
```python
from transformers import AutoModelForCausalLM, AutoTokenizer

def load_text_model():
    model = AutoModelForCausalLM.from_pretrained("meta-llama/Llama-3.2-3B")
    tokenizer = AutoTokenizer.from_pretrained("meta-llama/Llama-3.2-3B")
    return model, tokenizer
```

3. **Update route** in `apps/ai-server/src/routes/text_generation.py`

### Image Generation (Stable Diffusion Example)

1. **Download model**:
```bash
cd apps/ai-server/models/images
# Download Stable Diffusion XL
```

2. **Implement loading** in `apps/ai-server/src/services/image_service.py`:
```python
from diffusers import StableDiffusionXLPipeline
import torch

def load_image_model():
    pipe = StableDiffusionXLPipeline.from_pretrained(
        "stabilityai/stable-diffusion-xl-base-1.0",
        torch_dtype=torch.float16
    )
    pipe.to("cuda")
    return pipe
```

3. **Update route** in `apps/ai-server/src/routes/image_generation.py`

## ğŸŒ Using the AI Server in Next.js

### In API Routes (Server-Side)

```typescript
// apps/web/src/app/api/ai/generate/route.ts
import { aiClient } from '@fictures/api-client';

export async function POST(request: Request) {
  const { prompt } = await request.json();

  const result = await aiClient.generateText({
    prompt,
    max_tokens: 1024,
    temperature: 0.8,
  });

  return Response.json(result);
}
```

### In React Components (Client-Side)

```typescript
// apps/web/src/components/AIGenerator.tsx
'use client';

import { aiClient } from '@fictures/api-client';

export function AIGenerator() {
  const generate = async () => {
    const result = await aiClient.generateText({
      prompt: 'Write a story about...',
    });
    console.log(result.text);
  };

  return <button onClick={generate}>Generate</button>;
}
```

## ğŸš¢ Deployment

### Next.js â†’ Vercel
```bash
cd apps/web
vercel deploy
```

### Python AI Server â†’ Railway
```bash
cd apps/ai-server
railway up
```

**Alternative Platforms:**
- **Fly.io** - Containerized deployment
- **Modal Labs** - On-demand GPU inference
- **AWS/GCP** - Full control

## ğŸ§ª Testing

```bash
# Unit tests (Jest)
pnpm test
pnpm test:watch

# E2E tests (Playwright)
cd apps/web
dotenv --file .env.local run npx playwright test
```

## ğŸ“Š Project Status

- âœ… Monorepo structure with pnpm workspaces
- âœ… FastAPI server with OpenAPI documentation
- âœ… TypeScript client with type generation
- âœ… Development workflow configured
- â³ Add local AI models (your next step!)
- â³ Integrate AI endpoints in Next.js

## ğŸ¤ Contributing

1. Fork the repository
2. Create your feature branch: `git checkout -b feature/amazing-feature`
3. Commit your changes: `git commit -m 'Add amazing feature'`
4. Push to the branch: `git push origin feature/amazing-feature`
5. Open a Pull Request

## ğŸ“ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- **Next.js** - React framework
- **FastAPI** - Python web framework
- **Vercel AI SDK** - AI integration toolkit
- **Drizzle ORM** - TypeScript ORM
- **NextAuth.js** - Authentication
- **Hugging Face** - Model hub

## ğŸ“§ Support

- **Issues**: https://github.com/realbits-lab/Fictures/issues
- **Documentation**: See `docs/` directory
- **AI Server Docs**: http://localhost:8000/docs (when running)

---

Built with â¤ï¸ using Next.js, Python, and local AI models
