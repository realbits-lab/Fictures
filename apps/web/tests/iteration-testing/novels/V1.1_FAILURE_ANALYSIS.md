# v1.1 Part Prompt Failure Analysis

**Test Date**: 2025-11-15
**Test Story**: `story_bMom6GfrwSlfK_s3`
**Test Log**: `logs/v1.1-smoke-test-6.log`
**Status**: ❌ **HYPOTHESIS REJECTED** - v1.1 showed NO improvement over v1.0

---

## Executive Summary

The v1.1 part prompt explicitly required 5-phase cycle validation in chapter generation, but **failed to improve the Part Cycle Coherence metric**. Both v1.0 and v1.1 scored identically:

- **Cyclic Structure**: 79% (no change)
- **Intrinsic Motivation**: 75% (no change)
- **part.cycleCoherence**: **FAILED** (2/4 score - needs 3/4)

The analysis revealed a **fundamental misunderstanding** about what the Part Cycle Coherence metric actually measures.

---

## Root Cause Analysis

### What We Thought We Were Fixing

The v1.1 prompt added extensive 5-phase cycle requirements to the **chapter generation prompt**, including:

- Explicit 5-phase labels (Setup, Adversity, Virtue, Consequence, Transition)
- Validation checklist requiring ALL 5 phases
- Complete working example showing proper structure
- Output format validation

**Location of changes**: `/tests/iteration-testing/novels/prompts/v1.1/part-prompt.js` (350+ lines)

### What the Metric Actually Measures

The `part.cycleCoherence` metric doesn't evaluate chapter structure at all. Instead, it performs **keyword detection on the Part summary text**.

**Code Location**: `src/app/api/evaluation/part/route.ts:56-76`

```typescript
// Line 56: Evaluate metrics
const phasesPresent = detectPhases(part.summary || "");

const cycleCoherence = {
    ...createMetricResult({
        score: phasesPresent.length >= 4 ? 4 : phasesPresent.length >= 3 ? 3 : 2,
        target: 4,
        threshold: 3,
        feedback: "Cycle Coherence",
        method: "ai-evaluation" as const,
    }),
    details: {
        phasesPresent,
        phasesCount: phasesPresent.length,
        allPhasesDistinct: phasesPresent.length >= 4,
    },
};

// Line 137: Detection function
function detectPhases(text: string): string[] {
    const phaseKeywords = {
        setup: ["setup", "introduction", "begin"],
        adversity: ["adversity", "conflict", "struggle"],
        virtue: ["virtue", "goodness", "moral"],
        consequence: ["consequence", "result", "outcome"],
        transition: ["transition", "next", "following"],
    };

    const detected: string[] = [];
    const lowercaseText = text.toLowerCase();

    for (const [phase, keywords] of Object.entries(phaseKeywords)) {
        if (keywords.some((keyword) => lowercaseText.includes(keyword))) {
            detected.push(phase);
        }
    }

    return detected;
}
```

**What it checks**:
1. Reads the `part.summary` field from the database
2. Searches for phase keywords (case-insensitive)
3. Counts how many of the 5 phases have at least one matching keyword
4. Scores: 4+ phases = 4 points, 3 phases = 3 points, <3 phases = 2 points
5. Threshold: 3 points to pass

**What it DOES NOT check**:
- ❌ Chapter structure
- ❌ characterArcs fields
- ❌ Actual 5-phase cycle implementation
- ❌ Whether the AI model followed the prompt

---

## Actual Test Results

### Part Summary Generated (v1.1)

```
In the ruins of a war-torn city, Elena Maris, a refugee with a deep fear of
betrayal, begins cultivating a small garden as a symbol of hope and renewal.
As she faces the challenges of scarcity and distrust, her compassion and
resilience start to inspire others in the community. Meanwhile, a former
enemy soldier, unseen by Elena, secretly tends to her crops, planting seeds
of trust and healing in a broken world. Through their quiet acts of kindness,
they begin to rebuild not just a garden, but a fragile trust that might heal
the scars of war.
```

### Keyword Detection Results

**Phase Detection**:
- ✓ **setup**: Found keywords: `begin` (appears twice)
- ✗ **adversity**: No keywords found (looking for: adversity, conflict, struggle)
- ✗ **virtue**: No keywords found (looking for: virtue, goodness, moral)
- ✗ **consequence**: No keywords found (looking for: consequence, result, outcome)
- ✗ **transition**: No keywords found (looking for: transition, next, following)

**Score**: 1/5 phases detected → Score: 2/4 → **FAIL** ✗ (threshold: 3/4)

### Why Keywords Weren't Present

The part summary is a narrative description, not a technical specification. It naturally uses storytelling language like:
- "fear of betrayal" (internal conflict - not "adversity")
- "compassion and resilience" (character traits - not "virtue")
- "scarcity and distrust" (challenges - not "conflict")
- "inspire others" (impact - not "consequence")
- "rebuild... trust" (outcome - not "transition")

The AI model wrote a **good narrative summary** but didn't use the exact technical keywords the evaluation function was searching for.

---

## Why v1.1 Changes Had Zero Impact

### The Disconnect

1. **v1.1 prompt changes**: Modified chapter generation → affects `chapters.character_arc` field
2. **Part Cycle Coherence metric**: Reads `parts.summary` field → unaffected by chapter changes

### Database Investigation

**Chapters Table** (`story_bMom6GfrwSlfK_s3`):
- Chapter 1: "The First Sprout" - `character_arc` field: `null` or invalid
- Chapter 2: "The Whispering Roots" - `character_arc` field: `null` or invalid

**Parts Table** (`story_bMom6GfrwSlfK_s3`):
- Part 1: "The Seeds of Tomorrow"
- `summary`: Narrative description (shown above)
- `character_arcs`: Contains 3 character arc objects with `macroAdversity`, `macroVirtue`, `macroConsequence`, `macroNewAdversity` fields

**Conclusion**: The v1.1 part prompt generates the `parts.summary` field during **part generation phase**, not during chapter generation. Chapter-level changes cannot affect the part summary that was already written.

---

## Critical Insight: Generation Pipeline Timing

The novel generation pipeline runs in this order:

1. **Part Generation** → Creates `parts.summary` (evaluated by Part Cycle Coherence)
2. **Chapter Generation** → Creates `chapters.character_arc` (not evaluated)
3. **Scene Generation** → Creates actual story content

**v1.1 changes were in the chapter prompt**, which runs **AFTER** the part summary is already written and stored in the database.

---

## Implications for v1.2

### What Needs to Change

**Target**: Modify the **Part generation prompt** (not chapter prompt) to ensure the `part.summary` field contains the required phase keywords.

**Approaches**:

1. **Option A: Inject Keywords into Part Summary**
   - Require explicit phase labels in part summary
   - Example format: "**Setup**: Elena begins... **Adversity**: She faces... **Virtue**: Her compassion... **Consequence**: The garden becomes... **Transition**: Meanwhile, a soldier..."
   - Pros: Guaranteed to pass keyword detection
   - Cons: Unnatural, technical-sounding prose

2. **Option B: Improve Keyword Detection**
   - Expand keyword list to include natural narrative synonyms
   - Add semantic similarity detection (embeddings)
   - Pros: More flexible, works with natural prose
   - Cons: Requires changing evaluation code (scope creep)

3. **Option C: Change Evaluation Metric**
   - Evaluate chapter `character_arc` structure instead of part summary
   - Check for presence of all 5 phases in each chapter
   - Pros: Aligns metric with actual story structure
   - Cons: Requires evaluation API changes and database schema knowledge

4. **Option D: Add Explicit Phase Instructions to Part Prompt**
   - Modify part generation system prompt to include phase keywords naturally
   - Instruct model to use terms like "conflict", "virtue", "consequence" in summary
   - Pros: Natural prose + keyword alignment
   - Cons: Requires finding the part generation prompt

### Recommended Approach

**Short-term (v1.2)**: **Option D** - Find and modify the **part generation prompt** to naturally incorporate phase keywords

**Long-term**: **Option C** - Fix the evaluation metric to measure actual chapter structure, not part summary keywords

---

## Action Items for Next Session

1. **Locate Part Generation Prompt**
   - Search codebase for part generation system prompt
   - Likely location: `src/lib/studio/generators/` or similar
   - Look for prompt templates used during part creation

2. **Design v1.2 Part Prompt**
   - Add natural language instructions to use phase-related terms
   - Example: "When describing the part summary, naturally mention the central conflict (adversity), the virtue being tested, and the consequences of character choices"

3. **Test Keyword Coverage**
   - Analyze which keywords are most natural for narrative prose
   - Consider: "conflict" > "adversity", "struggle", "challenge"
   - Consider: "choice" > "virtue", "values", "principles"

4. **Smoke Test v1.2**
   - Run same test setup
   - Verify part summary contains 3+ phase keywords
   - Confirm Part Cycle Coherence passes

---

## Lessons Learned

### System Understanding Gap

- ❌ Assumed chapter structure was being evaluated
- ✓ Actual evaluation: simple keyword matching on part summary
- ❌ Modified wrong part of pipeline (chapter vs part)
- ✓ Need better understanding of evaluation metrics before changing prompts

### Documentation Gaps

The evaluation API code (`src/app/api/evaluation/part/route.ts`) was the source of truth, but:
- No documentation explaining keyword detection logic
- No specification of what "Part Cycle Coherence" actually measures
- Test plan assumed metric measured chapter structure

### Process Improvements

1. **Always inspect evaluation code first** before designing prompt changes
2. **Trace data flow** from generation → storage → evaluation
3. **Run targeted database queries** to see actual generated content
4. **Test assumptions** before implementing changes

---

## Conclusion

The v1.1 hypothesis failed because:
1. We modified the **chapter prompt** (wrong target)
2. The metric evaluates **part summary** (different data)
3. Keyword detection is **simplistic** (only checks for exact words)
4. Generation pipeline **timing** prevents chapter changes from affecting part summary

**Next version (v1.2)** must target the **part generation prompt** and ensure natural use of phase-related keywords in the part summary text.
